{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10338,"databundleVersionId":862042,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"427280bc","cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import transforms\nimport torchmetrics # torchmetrics for easy metric computation\nimport pytorch_lightning as pl # pytorch lightning for efficient and easy training implementation\nfrom pytorch_lightning.callbacks import ModelCheckpoint \nfrom pytorch_lightning.loggers import TensorBoardLogger # ModelCheckpoint and TensorboardLogger for checkpoint saving and logging\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{},"outputs":[],"execution_count":1},{"id":"b1a2cbfd","cell_type":"code","source":"def load_file(path):\n    return np.load(path).astype(np.float32)","metadata":{},"outputs":[],"execution_count":null},{"id":"23cf311b","cell_type":"code","source":"train_transforms = transforms.Compose([\n                                    transforms.ToTensor(),  # Convert numpy array to tensor\n                                    transforms.Normalize(0.49, 0.248),  # Use mean and std from preprocessing notebook\n                                    transforms.RandomAffine( # Data Augmentation\n                                        degrees=(-5, 5), translate=(0, 0.05), scale=(0.9, 1.1)),\n                                        transforms.RandomResizedCrop((224, 224), scale=(0.35, 1))\n\n])\n\nval_transforms = transforms.Compose([\n                                    transforms.ToTensor(),  # Convert numpy array to tensor\n                                    transforms.Normalize([0.49], [0.248]),  # Use mean and std from preprocessing notebook\n])\n\n\n","metadata":{},"outputs":[],"execution_count":null},{"id":"f3c0d902","cell_type":"code","source":"train_dataset = torchvision.datasets.DatasetFolder(\n    \"Processed/train/\",\n    loader=load_file, extensions=\"npy\", transform=train_transforms)\n\nval_dataset = torchvision.datasets.DatasetFolder(\n    \"Processed/val/\",\n    loader=load_file, extensions=\"npy\", transform=val_transforms)","metadata":{},"outputs":[],"execution_count":null},{"id":"a0aa2c69","cell_type":"code","source":"fig, axis = plt.subplots(2, 2, figsize=(9, 9))\nfor i in range(2):\n    for j in range(2):\n        random_index = np.random.randint(0, 20000)\n        x_ray, label = train_dataset[random_index]\n        axis[i][j].imshow(x_ray[0], cmap=\"bone\")\n        axis[i][j].set_title(f\"Label:{label}\")","metadata":{},"outputs":[],"execution_count":null},{"id":"28cee6cd","cell_type":"code","source":"import multiprocessing\n\nbatch_size = 8\nprint(multiprocessing.cpu_count())\nnum_workers = min(2, multiprocessing.cpu_count()) \n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\nprint(f\"There are {len(train_dataset)} train images and {len(val_dataset)} val images\")","metadata":{},"outputs":[],"execution_count":null},{"id":"b09067bb","cell_type":"code","source":"np.unique(train_dataset.targets, return_counts=True), np.unique(val_dataset.targets, return_counts=True)","metadata":{},"outputs":[],"execution_count":null},{"id":"0237c86e","cell_type":"code","source":"torchvision.models.resnet18()","metadata":{},"outputs":[],"execution_count":null},{"id":"680ec86b","cell_type":"code","source":"class PneumoniaModel(pl.LightningModule):\n    \n    def __init__(self, weight=1):\n        super().__init__()\n        \n        self.model = torchvision.models.resnet18()\n        # change conv1 from 3 to 1 input channels\n        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        # change out_feature of the last fully connected layer (called fc in resnet18) from 1000 to 1\n        self.model.fc = torch.nn.Linear(in_features=512, out_features=1)\n        \n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n        self.register_buffer(\"pos_weight\", torch.tensor([18593 / 5407]))\n        self.loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=self.pos_weight)\n        \n        # simple accuracy computation\n        self.train_acc = torchmetrics.Accuracy()\n        self.val_acc = torchmetrics.Accuracy()\n\n    def forward(self, data):\n    # Optional: print device info once\n        if not hasattr(self, 'device_logged'):\n            print(f\"Running model on device: {data.device}\")\n            self.device_logged = True\n\n        return self.model(data)\n    \n    def training_step(self, batch, batch_idx): # This method runs once per batch during the training loop in PyTorch Lightning.\n        x_ray, label = batch\n        label = label.float()  # Convert label to float (just needed for loss computation)\n        pred = self(x_ray)[:,0]  # Prediction: Make sure prediction and label have same shape\n        loss = self.loss_fn(pred, label)  # Compute the loss\n        \n        # Log loss and batch accuracy\n        self.log(\"Train Loss\", loss)\n        self.log(\"Step Train Acc\", self.train_acc(torch.sigmoid(pred), label.int()))\n        return loss\n    \n    \n    def training_epoch_end(self, outs):\n        # After one epoch compute the whole train_data accuracy\n        self.log(\"Train Acc\", self.train_acc.compute())\n        \n        \n    def validation_step(self, batch, batch_idx):\n        # Same steps as in the training_step\n        x_ray, label = batch\n        label = label.float()\n        pred = self(x_ray)[:,0]  # make sure prediction and label have same shape\n\n        loss = self.loss_fn(pred, label)\n        \n        # Log validation metrics\n        self.log(\"Val Loss\", loss)\n        self.log(\"Step Val Acc\", self.val_acc(torch.sigmoid(pred), label.int()))\n        return loss\n    \n    def validation_epoch_end(self, outs):\n        self.log(\"Val Acc\", self.val_acc.compute())\n    \n    def configure_optimizers(self):\n        #Caution! You always need to return a list here (just pack your optimizer into one :))\n        return [self.optimizer]\n","metadata":{},"outputs":[],"execution_count":null},{"id":"e0d10eb7","cell_type":"code","source":"model = PneumoniaModel()","metadata":{},"outputs":[],"execution_count":null},{"id":"6ea70e90","cell_type":"code","source":"model","metadata":{},"outputs":[],"execution_count":null},{"id":"d72c92cb","cell_type":"code","source":"# Create the checkpoint callback\ncheckpoint_callback = ModelCheckpoint(\n    monitor='Val Acc',\n    save_top_k=10,\n    mode='max')","metadata":{},"outputs":[],"execution_count":null},{"id":"a231949a","cell_type":"code","source":"if torch.cuda.is_available():\n    accelerator = \"gpu\"\n    devices = 1  # or \"auto\"\n    precision = 16\nelse:\n    accelerator = \"cpu\"\n    devices = 1\n    precision = 32\n\ntrainer = pl.Trainer(\n    accelerator=accelerator,\n    devices=devices,\n    precision=precision,\n    logger=TensorBoardLogger(save_dir=\"./logs\"),\n    log_every_n_steps=1,\n    callbacks=[checkpoint_callback],\n    max_epochs=35\n)","metadata":{},"outputs":[],"execution_count":null},{"id":"3152a097","cell_type":"code","source":"trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)","metadata":{},"outputs":[],"execution_count":null},{"id":"5153a221","cell_type":"markdown","source":"## Evaluation","metadata":{}},{"id":"79f09dbc","cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Use strict=False, otherwise we would want to match the pos_weight which is not necessary\nmodel = PneumoniaModel.load_from_checkpoint(\"weights/weights_1.ckpt\")\nmodel.eval()\nmodel.to(device);","metadata":{},"outputs":[],"execution_count":null},{"id":"8332630b","cell_type":"code","source":"preds = []\nlabels = []\n\nwith torch.no_grad():\n    for data, label in tqdm(val_dataset):\n        data = data.to(device).float().unsqueeze(0)\n        pred = torch.sigmoid(model(data)[0].cpu())\n        preds.append(pred)\n        labels.append(label)\npreds = torch.tensor(preds)\nlabels = torch.tensor(labels).int()","metadata":{},"outputs":[],"execution_count":null},{"id":"8d7359ca","cell_type":"code","source":"acc = torchmetrics.Accuracy()(preds, labels)\nprecision = torchmetrics.Precision()(preds, labels)\nrecall = torchmetrics.Recall()(preds, labels)\ncm = torchmetrics.ConfusionMatrix(num_classes=2)(preds, labels)\ncm_threshed = torchmetrics.ConfusionMatrix(num_classes=2, threshold=0.25)(preds, labels)\n\nprint(f\"Val Accuracy: {acc}\")\nprint(f\"Val Precision: {precision}\")\nprint(f\"Val Recall: {recall}\")\nprint(f\"Confusion Matrix:\\n {cm}\")\nprint(f\"Confusion Matrix 2:\\n {cm_threshed}\"","metadata":{},"outputs":[],"execution_count":null},{"id":"1d34bb1e","cell_type":"code","source":"fig, axis = plt.subplots(3, 3, figsize=(9, 9))\n\nfor i in range(3):\n    for j in range(3):\n        rnd_idx = np.random.randint(0, len(preds))\n        axis[i][j].imshow(val_dataset[rnd_idx][0][0], cmap=\"bone\")\n        axis[i][j].set_title(f\"Pred:{int(preds[rnd_idx] > 0.5)}, Label:{labels[rnd_idx]}\")\n        axis[i][j].axis(\"off\")","metadata":{},"outputs":[],"execution_count":null}]}