{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427280bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchmetrics # torchmetrics for easy metric computation\n",
    "import pytorch_lightning as pl # pytorch lightning for efficient and easy training implementation\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint \n",
    "from pytorch_lightning.loggers import TensorBoardLogger # ModelCheckpoint and TensorboardLogger for checkpoint saving and logging\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a2cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    return np.load(path).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                    transforms.ToTensor(),  # Convert numpy array to tensor\n",
    "                                    transforms.Normalize(0.49, 0.248),  # Use mean and std from preprocessing notebook\n",
    "                                    transforms.RandomAffine( # Data Augmentation\n",
    "                                        degrees=(-5, 5), translate=(0, 0.05), scale=(0.9, 1.1)),\n",
    "                                        transforms.RandomResizedCrop((224, 224), scale=(0.35, 1))\n",
    "\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "                                    transforms.ToTensor(),  # Convert numpy array to tensor\n",
    "                                    transforms.Normalize([0.49], [0.248]),  # Use mean and std from preprocessing notebook\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.DatasetFolder(\n",
    "    \"Processed/train/\",\n",
    "    loader=load_file, extensions=\"npy\", transform=train_transforms)\n",
    "\n",
    "val_dataset = torchvision.datasets.DatasetFolder(\n",
    "    \"Processed/val/\",\n",
    "    loader=load_file, extensions=\"npy\", transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aa2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(2, 2, figsize=(9, 9))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        random_index = np.random.randint(0, 20000)\n",
    "        x_ray, label = train_dataset[random_index]\n",
    "        axis[i][j].imshow(x_ray[0], cmap=\"bone\")\n",
    "        axis[i][j].set_title(f\"Label:{label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cee6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "batch_size = 8\n",
    "print(multiprocessing.cpu_count())\n",
    "num_workers = min(2, multiprocessing.cpu_count()) \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "\n",
    "print(f\"There are {len(train_dataset)} train images and {len(val_dataset)} val images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09067bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_dataset.targets, return_counts=True), np.unique(val_dataset.targets, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0237c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ec86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, weight=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = torchvision.models.resnet18()\n",
    "        # change conv1 from 3 to 1 input channels\n",
    "        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        # change out_feature of the last fully connected layer (called fc in resnet18) from 1000 to 1\n",
    "        self.model.fc = torch.nn.Linear(in_features=512, out_features=1)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        self.register_buffer(\"pos_weight\", torch.tensor([18593 / 5407]))\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
    "        \n",
    "        # simple accuracy computation\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.val_acc = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, data):\n",
    "    # Optional: print device info once\n",
    "        if not hasattr(self, 'device_logged'):\n",
    "            print(f\"Running model on device: {data.device}\")\n",
    "            self.device_logged = True\n",
    "\n",
    "        return self.model(data)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx): # This method runs once per batch during the training loop in PyTorch Lightning.\n",
    "        x_ray, label = batch\n",
    "        label = label.float()  # Convert label to float (just needed for loss computation)\n",
    "        pred = self(x_ray)[:,0]  # Prediction: Make sure prediction and label have same shape\n",
    "        loss = self.loss_fn(pred, label)  # Compute the loss\n",
    "        \n",
    "        # Log loss and batch accuracy\n",
    "        self.log(\"Train Loss\", loss)\n",
    "        self.log(\"Step Train Acc\", self.train_acc(torch.sigmoid(pred), label.int()))\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def training_epoch_end(self, outs):\n",
    "        # After one epoch compute the whole train_data accuracy\n",
    "        self.log(\"Train Acc\", self.train_acc.compute())\n",
    "        \n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Same steps as in the training_step\n",
    "        x_ray, label = batch\n",
    "        label = label.float()\n",
    "        pred = self(x_ray)[:,0]  # make sure prediction and label have same shape\n",
    "\n",
    "        loss = self.loss_fn(pred, label)\n",
    "        \n",
    "        # Log validation metrics\n",
    "        self.log(\"Val Loss\", loss)\n",
    "        self.log(\"Step Val Acc\", self.val_acc(torch.sigmoid(pred), label.int()))\n",
    "        return loss\n",
    "    \n",
    "    def validation_epoch_end(self, outs):\n",
    "        self.log(\"Val Acc\", self.val_acc.compute())\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        #Caution! You always need to return a list here (just pack your optimizer into one :))\n",
    "        return [self.optimizer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d10eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PneumoniaModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea70e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='Val Acc',\n",
    "    save_top_k=10,\n",
    "    mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a231949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    accelerator = \"gpu\"\n",
    "    devices = 1  # or \"auto\"\n",
    "    precision = 16\n",
    "else:\n",
    "    accelerator = \"cpu\"\n",
    "    devices = 1\n",
    "    precision = 32\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    precision=precision,\n",
    "    logger=TensorBoardLogger(save_dir=\"./logs\"),\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=35\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3152a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5153a221",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f09dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Use strict=False, otherwise we would want to match the pos_weight which is not necessary\n",
    "model = PneumoniaModel.load_from_checkpoint(\"weights/weights_1.ckpt\")\n",
    "model.eval()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, label in tqdm(val_dataset):\n",
    "        data = data.to(device).float().unsqueeze(0)\n",
    "        pred = torch.sigmoid(model(data)[0].cpu())\n",
    "        preds.append(pred)\n",
    "        labels.append(label)\n",
    "preds = torch.tensor(preds)\n",
    "labels = torch.tensor(labels).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7359ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = torchmetrics.Accuracy()(preds, labels)\n",
    "precision = torchmetrics.Precision()(preds, labels)\n",
    "recall = torchmetrics.Recall()(preds, labels)\n",
    "cm = torchmetrics.ConfusionMatrix(num_classes=2)(preds, labels)\n",
    "cm_threshed = torchmetrics.ConfusionMatrix(num_classes=2, threshold=0.25)(preds, labels)\n",
    "\n",
    "print(f\"Val Accuracy: {acc}\")\n",
    "print(f\"Val Precision: {precision}\")\n",
    "print(f\"Val Recall: {recall}\")\n",
    "print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Confusion Matrix 2:\\n {cm_threshed}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(3, 3, figsize=(9, 9))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        rnd_idx = np.random.randint(0, len(preds))\n",
    "        axis[i][j].imshow(val_dataset[rnd_idx][0][0], cmap=\"bone\")\n",
    "        axis[i][j].set_title(f\"Pred:{int(preds[rnd_idx] > 0.5)}, Label:{labels[rnd_idx]}\")\n",
    "        axis[i][j].axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
